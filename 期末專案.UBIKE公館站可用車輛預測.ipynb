{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 期末專案\n",
    "## ＊主題：UBIKE公館站可用車輛預測\n",
    "## ＊組員：羅正翰R07543051\n",
    "## ＊成功預測未來一小時之可用車輛"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、專案簡介：\n",
    "在台大校園中，大多的師生都是藉由腳踏車來代步。因此，光是在台大校園周圍，就設有7個UBIKE站。每站皆提供許多的腳踏車供大家使用。但許多時候仍供不應求，想騎腳踏車時卻撲了個空，要是能事先知道甚麼時後有車子可以騎就好了。因此，我希望能夠設計出一個神經網路能為UBIKE站點數量作短期預測，讓我們生活上的交通，變得更加便利。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、實作方法：\n",
    "## 1.數據來源\n",
    "### (1) APP  Bus+ =>提供台大周圍各站點即時的單車數\n",
    "### (2) google =>提供台大即時天氣資訊\n",
    "## 2.數據蒐集\n",
    "### (1) 撰寫網路爬蟲，每一分鐘上網爬取一筆資訊。\n",
    "### (2) 利用2個星期時間，爬取約16000筆資料。\n",
    "## 3.神經網路\n",
    "### (1) 輸入 => 星期、時、分、秒、降雨機率\n",
    "### (2) 輸出 => 預測之單車數量\n",
    "### (3) 模型 => 利用RNN循環式神經網路為主架構進行學習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、模型架構說明\n",
    "## 1. 訓練多個二分法模型。\n",
    "![結構說明1](結構說明1.jpg) \n",
    "## 2. 串聯多項模型，作為主架構。\n",
    "![結構說明2](結構說明2.jpg)\n",
    "## 3. 將預測結果分為：0 , 1 , 2~3 , 4~5 , 6~7 , 8~9 , 10 台以上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四、程式碼：\n",
    "## 1.爬蟲程式\n",
    "### (1)導入所需套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys \n",
    "from selenium import webdriver \n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "import csv,time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2)讀取現在時間，並將星期更改為數字1~7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#更改時間資訊，將星期轉為數字 : 1~7\n",
    "def time1():\n",
    "    \n",
    "    time_title=np.array(['日期','星期','時','分','秒','時間'])\n",
    "    date=time.strftime('%Y%m%d')\n",
    "    a=time.strftime('%a')\n",
    "    if a=='Mon':\n",
    "        a=1\n",
    "        \n",
    "    elif a=='Tue':\n",
    "        a=2\n",
    "        \n",
    "    elif a=='Wed':\n",
    "        a=3\n",
    "    \n",
    "    elif a=='Thu':\n",
    "        a=4\n",
    "        \n",
    "    elif a=='Fri':\n",
    "        a=5\n",
    "    \n",
    "    elif a=='Sat':\n",
    "        a=6\n",
    "    \n",
    "    elif a=='Sun':\n",
    "        a=7\n",
    "    hour=time.strftime('%H')\n",
    "    minute=time.strftime('%M')\n",
    "    second=time.strftime('%S')\n",
    "    time1=time.strftime('%H%M%S')\n",
    "    \n",
    "    data=np.array([date,a,hour,minute,second,time1])\n",
    "    data=data.reshape(1,6)\n",
    "    \n",
    "    data=pd.DataFrame(data,columns=time_title)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3)爬取台大即時天氣資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#抓取天氣資訊\n",
    "def weather(html):\n",
    "    driver = webdriver.Chrome()\n",
    "    first_url = html \n",
    "    driver.get(first_url) \n",
    "    time.sleep(2) #等待兩秒卻保有載入資料\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "    rain=soup.find('span',{'id':'wob_pp'})\n",
    "    \n",
    "    data=str(rain.get_text())\n",
    "    data=data.rstrip('%')\n",
    "    data=int(data)*0.01\n",
    "        \n",
    "    probability=np.zeros([1,1])\n",
    "    probability[0]=data\n",
    "    \n",
    "    driver.close()\n",
    "    \n",
    "    weather_title=np.array(['下雨機率'])\n",
    "    \n",
    "    data=pd.DataFrame(probability,columns=weather_title)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4)爬取台大周圍UBIKE站即時車輛資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#抓取台大周圍UBIKE各站之即時車輛資訊\n",
    "\n",
    "def ubike(html):\n",
    "\n",
    "    driver = webdriver.Chrome()\n",
    "    first_url = html \n",
    "    driver.get(first_url) \n",
    "    time.sleep(2) #等待兩秒卻保有載入資料\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "    area=soup.find_all('tr',{'data-area':'大安區'})\n",
    "    \n",
    "    #==============================================\n",
    "    #羅斯福新生南路站\n",
    "    \n",
    "    station1=area[25].find_all('td',{'style':''})\n",
    "\n",
    "    #可租借的腳踏車(available_bike)\n",
    "    a_b1=int(station1[2].get_text())\n",
    "\n",
    "    #可停放的位置(available_stop)\n",
    "    a_s1=int(station1[3].get_text())\n",
    "\n",
    "    #===============================================\n",
    "    #公館站\n",
    "    station2=area[10].find_all('td',{'style':''})\n",
    "\n",
    "    #可租借的腳踏車(available_bike)\n",
    "    a_b2=int(station2[2].get_text())\n",
    "\n",
    "    #可停放的位置(available_stop)\n",
    "    a_s2=int(station2[3].get_text())\n",
    "\n",
    "    #===============================================\n",
    "    #台灣科技大學站\n",
    "    station3=area[15].find_all('td',{'style':''})\n",
    "\n",
    "    #可租借的腳踏車(available_bike)\n",
    "    a_b3=int(station3[2].get_text())\n",
    "\n",
    "    #可停放的位置(available_stop)\n",
    "    a_s3=int(station3[3].get_text())\n",
    "\n",
    "    #===============================================\n",
    "    #基隆長興路口站\n",
    "    station4=area[4].find_all('td',{'style':''})\n",
    "\n",
    "    #可租借的腳踏車(available_bike)\n",
    "    a_b4=int(station4[2].get_text())\n",
    "\n",
    "    #可停放的位置(available_stop)\n",
    "    a_s4=int(station4[3].get_text())\n",
    "\n",
    "    #===============================================\n",
    "    #大安運動中心站\n",
    "    station5=area[33].find_all('td',{'style':''})\n",
    "\n",
    "    #可租借的腳踏車(available_bike)\n",
    "    a_b5=int(station5[2].get_text())\n",
    "\n",
    "    #可停放的位置(available_stop)\n",
    "    a_s5=int(station5[3].get_text())\n",
    "\n",
    "    #===============================================\n",
    "    #台大資訊大樓站\n",
    "    station6=area[7].find_all('td',{'style':''})\n",
    "\n",
    "    #可租借的腳踏車(available_bike)\n",
    "    a_b6=int(station6[2].get_text())\n",
    "\n",
    "    #可停放的位置(available_stop)\n",
    "    a_s6=int(station6[3].get_text())\n",
    "\n",
    "    #===============================================\n",
    "    #辛亥新生路口站\n",
    "    station7=area[5].find_all('td',{'style':''})\n",
    "\n",
    "    #可租借的腳踏車(available_bike)\n",
    "    a_b7=int(station7[2].get_text())\n",
    "\n",
    "    #可停放的位置(available_stop)\n",
    "    a_s7=int(station7[3].get_text())\n",
    "    \n",
    "    a_b_list=list([a_b1,a_b2,a_b3,a_b4,a_b5,a_b6,a_b7])\n",
    "    \n",
    "    a_s_list=list([a_s1,a_s2,a_s3,a_s4,a_s5,a_s6,a_s7])\n",
    "    \n",
    "    data=np.array(a_b_list+a_s_list)\n",
    "    data=data.reshape(2,7)\n",
    "    \n",
    "    driver.close()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4)網路爬蟲主程式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=np.array(['日期','星期','時','分','秒','時間','下雨機率',\n",
    "                '羅斯福新生南路','公館','台灣科技大學','基隆長興路口',\n",
    "                '大安運動中心','台大資訊大樓','辛亥新生路口'])\n",
    "\n",
    "a_bf=pd.DataFrame(columns=title)\n",
    "a_sf=pd.DataFrame(columns=title)\n",
    "\n",
    "count=0\n",
    "\n",
    "while True :\n",
    "    \n",
    "    time_data=time1()\n",
    "    \n",
    "    weather_data=weather('https://www.google.com/search?hl=zh-TW&source=hp&ei=fjHRXJ5cmOTzBbSTisgN&q=%E5%8F%B0%E5%A4%A7+%E5%A4%A9%E6%B0%A3&oq=&gs_l=psy-ab.1.0.35i39l6.0.0..4314...1.0..0.490.490.4-1......0......gws-wiz.....6.nzCpsl5uYOs')\n",
    "    \n",
    "    ubike_data=ubike('https://taipei.youbike.com.tw/station/list')\n",
    "    \n",
    "    a_b_array=ubike_data[0,:]\n",
    "    a_b_array=a_b_array.reshape(1,7)\n",
    "    \n",
    "    a_s_array=ubike_data[1,:]\n",
    "    a_s_array=a_s_array.reshape(1,7)\n",
    "    \n",
    "    station_title=np.array(['羅斯福新生南路','公館','台灣科技大學',\n",
    "                  '基隆長興路口','大安運動中心','台大資訊大樓','辛亥新生路口'])\n",
    "    \n",
    "    a_bf1=pd.DataFrame(a_b_array,columns=station_title)\n",
    "    a_sf1=pd.DataFrame(a_s_array,columns=station_title)\n",
    "    \n",
    "    a_bf1=pd.concat([time_data,weather_data,a_bf1],axis=1)\n",
    "    a_sf1=pd.concat([time_data,weather_data,a_sf1],axis=1)\n",
    "    \n",
    "    \n",
    "    a_bf=pd.concat([a_bf,a_bf1],axis=0)\n",
    "    a_sf=pd.concat([a_sf,a_sf1],axis=0)\n",
    "\n",
    "    \n",
    "    count=count+1\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    print('以抓取',count,'筆資料')\n",
    "    \n",
    "    a_bf.to_csv('5.14_05_a_bf.csv', index = False)\n",
    "    a_sf.to_csv('5.14_05_a_sf.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.子神經網路訓練\n",
    "### (1)導入所需套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "%env KERAS_BACKEND=tensorflow\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras import optimizers\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2)將資料做2分法，大於等於n台車為一類，小於n台車為一類。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category(data,num):\n",
    "    \n",
    "    length=len(data)\n",
    "    \n",
    "    category=np.ones(length)\n",
    "    \n",
    "    for i in range(0,length):\n",
    "        if (data[i] == num):\n",
    "                \n",
    "            category[i]=0\n",
    "                \n",
    "    \n",
    "    category=category.reshape(length,1)\n",
    "    category = pd.DataFrame(category, columns=['公館分類'])\n",
    "\n",
    "    return category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3)將資料區分成training data 及 testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(x_data,y_data,test_num,random):\n",
    "    real_test_num=100\n",
    "    if random==True:\n",
    "        x_data = x_data.sample(frac=1)\n",
    "        y_data = y_data.sample(frac=1)\n",
    "    \n",
    "    x_data=np.array(x_data)\n",
    "    y_data=np.array(y_data)\n",
    "    \n",
    "    data_num=len(x_data)\n",
    "    \n",
    "    x_real_test=x_data[data_num-real_test_num:data_num]\n",
    "    y_real_test=y_data[data_num-real_test_num:data_num]\n",
    "    \n",
    "    x_test=x_data[data_num-real_test_num-test_num:data_num-real_test_num]\n",
    "    y_test=y_data[data_num-real_test_num-test_num:data_num-real_test_num]\n",
    "    \n",
    "    x_train=x_data[0:data_num-real_test_num-test_num]\n",
    "    y_train=y_data[0:data_num-real_test_num-test_num]\n",
    "    \n",
    "    return x_train,x_test,x_real_test,y_train,y_test,y_real_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4)從讀取到模型訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============資料讀取及整理=============\n",
    "a_bf=pd.read_csv('a_bf.csv')\n",
    "\n",
    "x1=a_bf['星期']\n",
    "x2=a_bf['時']\n",
    "x3=a_bf['分']\n",
    "x4=a_bf['秒']\n",
    "x5=a_bf['下雨機率']\n",
    "\n",
    "y1=category(a_bf.公館,0)\n",
    "\n",
    "x_data=pd.concat([x1,x2,x3,x4,x5],axis=1)\n",
    "y_data=y1\n",
    "\n",
    "x_train,x_test,x_real_test,y_train,y_test,y_real_test=sample(x_data,y_data,1000,False)\n",
    "\n",
    "y_train_c=np_utils.to_categorical(y_train,2)\n",
    "y_test_c=np_utils.to_categorical(y_test,2)\n",
    "\n",
    "#===============神經網路架構建立=============\n",
    "\n",
    "N = 1000 # 文字要壓到 N 維\n",
    "M = 1000 # LSTM 有 K 個神經元\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, N))\n",
    "\n",
    "model.add(LSTM(M,return_sequences=False))\n",
    "\n",
    "Adm=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, \n",
    "                epsilon=None, decay=0.0, amsgrad=False)          \n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='mse',optimizer=Adm,metrics=['accuracy'])\n",
    "\n",
    "#===============神經網路訓練=============\n",
    "\n",
    "model.fit(x_train, y_train_c)\n",
    "\n",
    "#===============將模型儲存=============\n",
    "\n",
    "model.json=model.to_json()\n",
    "open('0_model.json','w').write(model.json)\n",
    "model.save_weights('0_model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.多層神經網路串聯\n",
    "### (1)導入所需套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import model_from_json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2)讀取各分類方法之模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0=model_from_json(open('0_model.json').read())\n",
    "model_1=model_from_json(open('1_model.json').read())\n",
    "model_2=model_from_json(open('2_model.json').read())\n",
    "model_4=model_from_json(open('4_model.json').read())\n",
    "model_6=model_from_json(open('6_model.json').read())\n",
    "model_8=model_from_json(open('8_model.json').read())\n",
    "model_10=model_from_json(open('10_model.json').read())\n",
    "\n",
    "model_0.load_weights('0_model_weights.h5')\n",
    "model_1.load_weights('1_model_weights.h5')\n",
    "model_2.load_weights('2_model_weights.h5')\n",
    "model_4.load_weights('4_model_weights.h5')\n",
    "model_6.load_weights('6_model_weights.h5')\n",
    "model_8.load_weights('8_model_weights.h5')\n",
    "model_10.load_weights('10_model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3)將上層模型分類之資料下傳至下層模型繼續分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descent(test_data1,model_num):\n",
    "    model=model_num\n",
    "    \n",
    "    df=test_data1\n",
    "    \n",
    "    x_test=df[['星期','時','分','秒','下雨機率']]\n",
    "    x_test=np.array(x_test)\n",
    "    \n",
    "    test_predict=model.predict_classes(x_test)\n",
    "    test_predict=test_predict.reshape(len(test_predict),1)\n",
    "    \n",
    "    df.分類=test_predict\n",
    "    \n",
    "    condition0=(df.分類==0) #小於\n",
    "    condition1=(df.分類==1) #大於 等於\n",
    "    \n",
    "    first=df[condition0]\n",
    "\n",
    "    second=df[condition1]\n",
    "\n",
    "    \n",
    "    return first,second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4)讀取testing data，並進行預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============testing data 讀取===============\n",
    "\n",
    "test_data=pd.read_csv('test_data(train).csv')\n",
    "\n",
    "#===============testing data 預測===============\n",
    "\n",
    "df=pd.DataFrame( columns=['星期','時','分','秒','下雨機率','數量','分類','正確'])\n",
    "\n",
    "data_b0,data_a0=descent(test_data,model_0)\n",
    "if len(data_b0)>0:\n",
    "    data_b0.分類=0\n",
    "    condition=(data_b0.數量==0)\n",
    "    data_b0.正確=condition\n",
    "    print('0_num:',len(data_b0))\n",
    "    df=data_b0\n",
    "else:\n",
    "    print('0_num:',0)\n",
    "#=====================================model_0\n",
    "if len(data_a0)>0:\n",
    "    data_b2,data_a2=descent(data_a0,model_2)\n",
    "\n",
    "    if len(data_b2)>0:\n",
    "        data_b2.分類=1\n",
    "        condition=(data_b2.數量==1)\n",
    "        data_b2.正確=condition\n",
    "        print('1_num:',len(data_b2))\n",
    "        df=pd.concat([df,data_b2],axis=0)\n",
    "    else:\n",
    "        print('1_num:',0)\n",
    "    #=====================================model_2\n",
    "    if len(data_a2)>0:\n",
    "        data_b4,data_a4=descent(data_a2,model_4)\n",
    "\n",
    "        if len(data_b4)>0:\n",
    "            data_b4.分類=2.3\n",
    "            condition1=(data_b4.數量==2)\n",
    "            condition2=(data_b4.數量==3)\n",
    "            data_b4.正確=condition1+condition2\n",
    "            print('2.3_num:',len(data_b4))\n",
    "            df=pd.concat([df,data_b4],axis=0)\n",
    "        else:\n",
    "            print('2.3_num:',0)\n",
    "        #=====================================model_4\n",
    "        if len(data_a4)>0:\n",
    "            data_b6,data_a6=descent(data_a4,model_6)\n",
    "\n",
    "            if len(data_b6)>0:\n",
    "                data_b6.分類=4.5\n",
    "                condition1=(data_b6.數量==4)\n",
    "                condition2=(data_b6.數量==5)\n",
    "                data_b6.正確=condition1+condition2\n",
    "                print('4.5_num:',len(data_b6))\n",
    "                df=pd.concat([df,data_b6],axis=0)\n",
    "            else:\n",
    "                print('4.5_num:',0)\n",
    "            #=====================================model_6\n",
    "            if len(data_a6)>0:\n",
    "                data_b8,data_a8=descent(data_a6,model_8)\n",
    "\n",
    "                if len(data_b8)>0:\n",
    "                    data_b8.分類=6.7\n",
    "                    condition1=(data_b8.數量==6)\n",
    "                    condition2=(data_b8.數量==7)\n",
    "                    data_b8.正確=condition1+condition2\n",
    "                    print('6.7_num:',len(data_b8))\n",
    "                    df=pd.concat([df,data_b8],axis=0)\n",
    "                else:\n",
    "                    print('6.7_num:',0)\n",
    "                #=====================================model_8\n",
    "                if len(data_a8)>0:\n",
    "                    data_b10,data_a10=descent(data_a8,model_10)\n",
    "\n",
    "                    if len(data_b10)>0:\n",
    "                        data_b10.分類=8.9\n",
    "                        condition1=(data_b10.數量==8)\n",
    "                        condition2=(data_b10.數量==9)\n",
    "                        data_b10.正確=condition1+condition2\n",
    "                        print('8.9_num:',len(data_b10))\n",
    "                        df=pd.concat([df,data_b10],axis=0)\n",
    "                    else:\n",
    "                        print('8.9_num:',0)\n",
    "                    if len(data_a10)>0:\n",
    "                        data_a10.分類=10\n",
    "                        condition=(data_a10.數量>9)\n",
    "                        data_a10.正確=condition\n",
    "                        print('10_num:',len(data_a10))\n",
    "                        df=pd.concat([df,data_a10],axis=0)\n",
    "                    else:\n",
    "                        print('10_num:',0)\n",
    "\n",
    "                        \n",
    "#===============將預測結果，以pandas 按照時間順序 輸出===============\n",
    "\n",
    "df=df.sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 五、預測結果分析及討論\n",
    "## 1. 預測1000筆testing data(約為24Hr)\n",
    "### (1) 真實數量及預測數量比較\n",
    "![預測結果1](predict v.s real2.png)\n",
    "![預測結果2](predict v.s real.png)\n",
    "*上圖，為真實數量與預測數量的比較，其中預測數量中的10，代表神經網路判斷為10台以上。\n",
    "\n",
    "*下圖，將真實數量10台以上的情況，都改設為10，更適合與預測情形比較。\n",
    "\n",
    "### (2) 觀察準確度隨時間的變化\n",
    "![預測結果3](acc decay with time_muti-layers.png)\n",
    "\n",
    "*資料預測的準確度，隨時間的增長而成指數快速下降\n",
    "\n",
    "*當資料數<20時(約為20分鐘以內)，準確度可達 100%\n",
    "\n",
    "*當資料數<25時(約為25分鐘以內)，準確度可達 80%\n",
    "\n",
    "*當資料數<50時(約為50分鐘以內)，準確度可達 60%\n",
    "\n",
    "## 2. 結果討論\n",
    "\n",
    "若以準確度60%，作為最低可靠標準。則本專案中，可靠預測範圍為未來50分鐘。\n",
    "\n",
    "若能加長網路爬蟲爬取資料的時間(1個月、甚至1年)，藉以增加training data的數量，也許testing data的可靠預測範圍能變得更大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 附錄\n",
    "## 1. 嘗試過多種訓練模型(以最終模型表現最佳)\n",
    "### (1)NN\n",
    "![神經網路模型1](神經網路模型1.jpg)\n",
    "### (2)RNN with LSTM\n",
    "![神經網路模型2](神經網路模型2.jpg)\n",
    "### (3)RNN with GRU\n",
    "![神經網路模型3](神經網路模型3.jpg)\n",
    "### (4)NN +RNN\n",
    "![神經網路模型4](神經網路模型4.jpg)\n",
    "\n",
    "## 2. 以不同車數為基準做二分法的表現情形\n",
    "### (1)0~8\n",
    "![0~8](acc decay with time_model_0-8.png)\n",
    "### (2)10~18\n",
    "![10~18](acc decay with time_model_10-18.png)\n",
    "### (3)20~30\n",
    "![20~30](acc decay with time_model_20-30.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
